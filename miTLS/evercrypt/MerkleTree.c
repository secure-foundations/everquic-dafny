/* 
  This file was generated by KreMLin <https://github.com/FStarLang/kremlin>
  KreMLin invocation: /home/everest/everest/kremlin/krml -bundle Lib.RandomBuffer.System= -bundle Lib.PrintBuffer= -add-include "evercrypt_targetconfig.h" -bundle Test,Test.*,Hacl.Test.* -ccopts -march=native,-mtune=native -add-include "libintvector.h" -bundle Hacl.Hash.MD5+Hacl.Hash.Core.MD5+Hacl.Hash.SHA1+Hacl.Hash.Core.SHA1+Hacl.Hash.SHA2+Hacl.Hash.Core.SHA2+Hacl.Hash.Core.SHA2.Constants=Hacl.Hash.*[rename=Hacl_Hash] -bundle EverCrypt.Hash+EverCrypt.Hash.Incremental=[rename=EverCrypt_Hash] -bundle Hacl.Impl.SHA3+Hacl.SHA3=[rename=Hacl_SHA3] -bundle Hacl.Chacha20=Hacl.Impl.Chacha20,Hacl.Impl.Chacha20.* -bundle Hacl.Salsa20=Hacl.Impl.Salsa20,Hacl.Impl.Salsa20.*,Hacl.Impl.HSalsa20 -bundle Hacl.Curve25519_64=Hacl.Impl.Curve25519.Field64.Vale -bundle Hacl.Curve25519_64_Slow=Hacl.Impl.Curve25519.Field64.Hacl,Hacl.Spec.Curve25519,Hacl.Spec.Curve25519.\* -bundle Hacl.Curve25519_51=Hacl.Impl.Curve25519.Field51 -bundle Hacl.Impl.Curve25519.\*[rename=Hacl_Curve_Leftovers] -bundle Hacl.Curve25519_64_Local -bundle Hacl.Impl.Chacha20Poly1305 -bundle Hacl.Ed25519=Hacl.Impl.Ed25519.*,Hacl.Impl.BignumQ.Mul,Hacl.Impl.Load56,Hacl.Impl.SHA512.ModQ,Hacl.Impl.Store56,Hacl.Bignum25519 -bundle Hacl.Poly1305_32=Hacl.Impl.Poly1305.Field32xN_32 -bundle Hacl.Poly1305_128=Hacl.Impl.Poly1305.Field32xN_128 -bundle Hacl.Poly1305_256=Hacl.Impl.Poly1305.Field32xN_256 -bundle Hacl.NaCl=Hacl.Impl.SecretBox,Hacl.Impl.Box -bundle MerkleTree.New.Low+MerkleTree.New.Low.Serialization=[rename=MerkleTree] -bundle WasmSupport -bundle EverCrypt.CTR=EverCrypt.CTR.* -bundle Hacl.Frodo.KEM=Frodo.Params,Hacl.Impl.Frodo.*,Hacl.Impl.Matrix,Hacl.Frodo.*,Hacl.Keccak -bundle Hacl.Poly1305.Field32xN.Lemmas[rename=Hacl_Lemmas] -drop EverCrypt.TargetConfig -bundle EverCrypt.BCrypt -bundle EverCrypt.OpenSSL -bundle MerkleTree.Spec,MerkleTree.Spec.*,MerkleTree.New.High,MerkleTree.New.High.* -bundle Vale.Stdcalls.*,Vale.Interop,Vale.Interop.*,Vale.Wrapper.X64.*[rename=Vale] -bundle Vale.Inline.X64.*[rename=Vale_Inline] -bundle Vale.*[rename=Unused2] -library Vale.Stdcalls.* -no-prefix Vale.Stdcalls.* -static-header Vale_Inline -library Vale.Inline.X64.Fadd_inline -library Vale.Inline.X64.Fmul_inline -library Vale.Inline.X64.Fswap_inline -library Vale.Inline.X64.Fsqr_inline -no-prefix Vale.Inline.X64.Fadd_inline -no-prefix Vale.Inline.X64.Fmul_inline -no-prefix Vale.Inline.X64.Fswap_inline -no-prefix Vale.Inline.X64.Fsqr_inline -no-prefix EverCrypt.Vale -add-include Hacl_Curve25519_64:"curve25519-inline.h" -no-prefix MerkleTree.New.Low -no-prefix MerkleTree.New.Low.Serialization -bundle Hacl.Impl.Poly1305.Fields -bundle EverCrypt.Spec.* -library EverCrypt.AutoConfig,EverCrypt.OpenSSL,EverCrypt.BCrypt -no-prefix Hacl.Frodo.Random -bundle Hacl.Spec.*,Spec.*[rename=Hacl_Spec] -bundle Lib.*[rename=Hacl_Lib] -drop Lib.IntVector.Intrinsics -fparentheses -fno-shadow -fcurly-braces -bundle LowStar.* -bundle Prims,C.Failure,C,C.String,C.Loops,Spec.Loops,C.Endianness,FStar.*[rename=Hacl_Kremlib] -bundle Meta.* -minimal -add-include "kremlin/internal/types.h" -add-include "kremlin/lowstar_endianness.h" -add-include <string.h> -add-include "kremlin/internal/target.h" -ctypes EverCrypt.Ed25519 -tmpdir dist/compact/ -skip-compilation obj/prims.krml obj/FStar_Pervasives_Native.krml obj/FStar_Pervasives.krml obj/FStar_Squash.krml obj/FStar_Classical.krml obj/FStar_FunctionalExtensionality.krml obj/FStar_Set.krml obj/FStar_Map.krml obj/FStar_StrongExcludedMiddle.krml obj/FStar_List_Tot_Base.krml obj/FStar_List_Tot_Properties.krml obj/FStar_List_Tot.krml obj/FStar_Seq_Base.krml obj/FStar_Seq_Properties.krml obj/FStar_Seq.krml obj/FStar_Mul.krml obj/Vale_Lib_Seqs_s.krml obj/FStar_Preorder.krml obj/FStar_Calc.krml obj/FStar_Math_Lib.krml obj/FStar_Math_Lemmas.krml obj/FStar_BitVector.krml obj/FStar_UInt.krml obj/FStar_UInt32.krml obj/FStar_UInt8.krml obj/Vale_Def_Words_s.krml obj/Vale_Def_Words_Four_s.krml obj/Vale_Def_Words_Two_s.krml obj/Vale_Def_Words_Seq_s.krml obj/Vale_Def_Opaque_s.krml obj/Vale_Def_Types_s.krml obj/Vale_X64_Machine_s.krml obj/Vale_Lib_Map16.krml obj/Vale_Def_Prop_s.krml obj/Vale_X64_Flags.krml obj/Vale_AES_AES_s.krml obj/FStar_Float.krml obj/FStar_UInt64.krml obj/FStar_Exn.krml obj/FStar_Monotonic_Witnessed.krml obj/FStar_Ghost.krml obj/FStar_ErasedLogic.krml obj/FStar_PropositionalExtensionality.krml obj/FStar_PredicateExtensionality.krml obj/FStar_TSet.krml obj/FStar_Monotonic_Heap.krml obj/FStar_Heap.krml obj/FStar_ST.krml obj/FStar_All.krml obj/FStar_IO.krml obj/Vale_Def_PossiblyMonad.krml obj/FStar_List.krml obj/Vale_Lib_Meta.krml obj/Vale_Def_Words_Two.krml obj/Vale_Lib_Seqs.krml obj/Vale_Def_TypesNative_s.krml obj/Vale_Arch_TypesNative.krml obj/Vale_Def_Words_Seq.krml obj/Vale_Arch_Types.krml obj/FStar_UInt16.krml obj/FStar_Monotonic_HyperHeap.krml obj/FStar_Monotonic_HyperStack.krml obj/FStar_HyperStack.krml obj/FStar_HyperStack_ST.krml obj/FStar_Universe.krml obj/FStar_GSet.krml obj/FStar_ModifiesGen.krml obj/FStar_Range.krml obj/FStar_Reflection_Types.krml obj/FStar_Tactics_Types.krml obj/FStar_Tactics_Result.krml obj/FStar_Tactics_Effect.krml obj/FStar_Tactics_Util.krml obj/FStar_Reflection_Data.krml obj/FStar_Reflection_Const.krml obj/FStar_Char.krml obj/FStar_String.krml obj/FStar_Order.krml obj/FStar_Reflection_Basic.krml obj/FStar_Reflection_Derived.krml obj/FStar_Tactics_Builtins.krml obj/FStar_Reflection_Formula.krml obj/FStar_Reflection_Derived_Lemmas.krml obj/FStar_Reflection.krml obj/FStar_Tactics_Derived.krml obj/FStar_Tactics_Logic.krml obj/FStar_Tactics.krml obj/FStar_BigOps.krml obj/LowStar_Monotonic_Buffer.krml obj/LowStar_BufferView_Down.krml obj/LowStar_BufferView_Up.krml obj/Vale_Interop_Views.krml obj/FStar_Option.krml obj/Vale_Lib_Set.krml obj/Vale_X64_Instruction_s.krml obj/Vale_X64_Bytes_Code_s.krml obj/Vale_Math_Poly2_Defs_s.krml obj/Vale_Math_Poly2_s.krml obj/Vale_Math_Poly2_Bits_s.krml obj/Lib_LoopCombinators.krml obj/FStar_Int.krml obj/FStar_Int64.krml obj/FStar_Int63.krml obj/FStar_Int32.krml obj/FStar_Int16.krml obj/FStar_Int8.krml obj/FStar_UInt63.krml obj/FStar_Int_Cast.krml obj/FStar_UInt128.krml obj/FStar_Int_Cast_Full.krml obj/FStar_Int128.krml obj/Lib_IntTypes.krml obj/Lib_RawIntTypes.krml obj/Lib_Sequence.krml obj/Lib_ByteSequence.krml obj/Spec_Hash_Definitions.krml obj/Spec_Hash_Lemmas0.krml obj/Spec_Hash_PadFinish.krml obj/Spec_Loops.krml obj/Spec_SHA2_Constants.krml obj/Spec_SHA2.krml obj/Vale_X64_CryptoInstructions_s.krml obj/Vale_X64_CPU_Features_s.krml obj/Vale_X64_Instructions_s.krml obj/LowStar_Buffer.krml obj/Vale_Arch_HeapTypes_s.krml obj/Vale_Interop_Types.krml obj/Vale_Arch_MachineHeap_s.krml obj/Vale_Interop_Heap_s.krml obj/LowStar_Modifies.krml obj/LowStar_ModifiesPat.krml obj/LowStar_BufferView.krml obj/Vale_Lib_BufferViewHelpers.krml obj/Vale_Interop.krml obj/Vale_Arch_HeapImpl.krml obj/Vale_Arch_Heap.krml obj/Vale_X64_Machine_Semantics_s.krml obj/LowStar_ImmutableBuffer.krml obj/Vale_Interop_Base.krml obj/Vale_X64_Memory.krml obj/Vale_Arch_MachineHeap.krml obj/Vale_X64_Stack_i.krml obj/Vale_X64_Stack_Sems.krml obj/Vale_X64_BufferViewStore.krml obj/Vale_X64_Memory_Sems.krml obj/Vale_X64_Regs.krml obj/Vale_X64_State.krml obj/Vale_X64_StateLemmas.krml obj/Vale_X64_Lemmas.krml obj/Vale_X64_Print_s.krml obj/Vale_X64_Decls.krml obj/Vale_X64_Taint_Semantics.krml obj/Vale_X64_InsLemmas.krml obj/Vale_X64_QuickCode.krml obj/Vale_X64_InsAes.krml obj/Spec_Chacha20.krml obj/Meta_Attribute.krml obj/LowStar_BufferOps.krml obj/C_Loops.krml obj/Lib_Loops.krml obj/FStar_Endianness.krml obj/LowStar_Endianness.krml obj/Lib_Buffer.krml obj/Lib_ByteBuffer.krml obj/FStar_HyperStack_All.krml obj/Lib_IntVector_Intrinsics.krml obj/Spec_GaloisField.krml obj/Spec_AES.krml obj/Lib_IntVector.krml obj/Hacl_Spec_Chacha20_Vec.krml obj/Hacl_Spec_Chacha20_Lemmas.krml obj/Lib_Sequence_Lemmas.krml obj/Hacl_Spec_Chacha20_Equiv.krml obj/Hacl_Impl_Chacha20_Core32xN.krml obj/Hacl_Impl_Chacha20_Vec.krml obj/Vale_Curve25519_Fast_lemmas_internal.krml obj/Vale_Curve25519_Fast_defs.krml obj/FStar_Algebra_CommMonoid.krml obj/FStar_Tactics_CanonCommSemiring.krml obj/Vale_Curve25519_FastUtil_helpers.krml obj/Vale_Curve25519_FastHybrid_helpers.krml obj/Vale_Curve25519_Fast_lemmas_external.krml obj/Vale_X64_QuickCodes.krml obj/Vale_X64_InsBasic.krml obj/Vale_X64_InsMem.krml obj/Vale_X64_InsVector.krml obj/Vale_X64_InsStack.krml obj/Vale_Curve25519_X64_FastHybrid.krml obj/Vale_Bignum_Defs.krml obj/Vale_Bignum_X64.krml obj/Vale_Curve25519_FastSqr_helpers.krml obj/Vale_Curve25519_X64_FastSqr.krml obj/Vale_Curve25519_FastMul_helpers.krml obj/Vale_Curve25519_X64_FastMul.krml obj/Vale_Curve25519_X64_FastWide.krml obj/Vale_Curve25519_X64_FastUtil.krml obj/Vale_X64_MemoryAdapters.krml obj/Vale_Interop_Assumptions.krml obj/Vale_Interop_X64.krml obj/Vale_AsLowStar_ValeSig.krml obj/Vale_AsLowStar_LowStarSig.krml obj/Vale_AsLowStar_MemoryHelpers.krml obj/Vale_AsLowStar_Wrapper.krml obj/Vale_Stdcalls_X64_Fadd.krml obj/Vale_Wrapper_X64_Fadd.krml obj/Lib_Meta.krml obj/Spec_HMAC_DRBG_Test_Vectors.krml obj/Vale_Math_Poly2_Defs.krml obj/Vale_Math_Poly2.krml obj/Vale_Math_Poly2_Lemmas.krml obj/Vale_Math_Poly2_Bits.krml obj/Vale_Math_Poly2_Words.krml obj/Vale_AES_GF128_s.krml obj/Vale_AES_GF128.krml obj/Vale_AES_OptPublic.krml obj/Vale_AES_X64_GF128_Mul.krml obj/Vale_AES_X64_PolyOps.krml obj/Vale_X64_Stack.krml obj/FStar_BV.krml obj/Vale_Lib_Bv_s.krml obj/Vale_Math_Bits.krml obj/Vale_Lib_Tactics.krml obj/FStar_Reflection_Arith.krml obj/FStar_Tactics_BV.krml obj/Vale_Poly1305_Bitvectors.krml obj/Vale_AES_GCTR_s.krml obj/Vale_AES_GCM_helpers.krml obj/Vale_AES_GCTR.krml obj/Vale_AES_AES256_helpers.krml obj/Vale_AES_X64_AES256.krml obj/Vale_AES_AES_helpers.krml obj/Vale_AES_X64_AES128.krml obj/Vale_AES_X64_AES.krml obj/Vale_AES_GHash_s.krml obj/Vale_AES_GHash.krml obj/Vale_AES_X64_GF128_Init.krml obj/Vale_Transformers_Locations.krml obj/Spec_SHA1.krml obj/Spec_MD5.krml obj/Spec_Agile_Hash.krml obj/Spec_Hash_Incremental.krml obj/Spec_Hash_Lemmas.krml obj/FStar_Kremlin_Endianness.krml obj/Hacl_Hash_Lemmas.krml obj/Hacl_Hash_Definitions.krml obj/Hacl_Hash_PadFinish.krml obj/Hacl_Hash_MD.krml obj/Spec_SHA2_Lemmas.krml obj/Vale_SHA_SHA_helpers.krml obj/Vale_X64_InsSha.krml obj/Vale_SHA_X64.krml obj/Vale_Stdcalls_X64_Sha.krml obj/Vale_Math_Lemmas_Int.krml obj/FStar_Tactics_Canon.krml obj/Vale_Poly1305_Spec_s.krml obj/Vale_Poly1305_Math.krml obj/Vale_Poly1305_Util.krml obj/Vale_Poly1305_X64.krml obj/Vale_Stdcalls_X64_Poly.krml obj/Vale_Wrapper_X64_Poly.krml obj/Vale_Arch_BufferFriend.krml obj/Vale_SHA_Simplify_Sha.krml obj/Vale_Wrapper_X64_Sha.krml obj/Hacl_Hash_Core_SHA2_Constants.krml obj/Hacl_Hash_Core_SHA2.krml obj/Hacl_Hash_SHA2.krml obj/Hacl_Hash_Core_SHA1.krml obj/Hacl_Hash_SHA1.krml obj/Hacl_Hash_Core_MD5.krml obj/Hacl_Hash_MD5.krml obj/C_Endianness.krml obj/C.krml obj/C_String.krml obj/C_Failure.krml obj/FStar_Int31.krml obj/FStar_UInt31.krml obj/FStar_Integers.krml obj/EverCrypt_StaticConfig.krml obj/EverCrypt_TargetConfig.krml obj/Vale_Lib_Basic.krml obj/Vale_Lib_X64_Cpuid.krml obj/Vale_Lib_X64_Cpuidstdcall.krml obj/Vale_Stdcalls_X64_Cpuid.krml obj/Vale_Wrapper_X64_Cpuid.krml obj/EverCrypt_AutoConfig2.krml obj/EverCrypt_Helpers.krml obj/EverCrypt_Hash.krml obj/Spec_SHA3_Constants.krml obj/Spec_Curve25519_Lemmas.krml obj/Spec_Curve25519.krml obj/Spec_Ed25519.krml obj/Hacl_Spec_Ed25519_Field56_Definition.krml obj/Hacl_Impl_Ed25519_Field56.krml obj/Hacl_Spec_Curve25519_Field51_Definition.krml obj/Hacl_Impl_Curve25519_Lemmas.krml obj/Hacl_Spec_Curve25519_Field51_Lemmas.krml obj/Hacl_Spec_Curve25519_Field51.krml obj/Hacl_Spec_Curve25519_Field64_Definition.krml obj/Hacl_Spec_Curve25519_Field64_Lemmas.krml obj/Hacl_Spec_Curve25519_Field64_Core.krml obj/Hacl_Spec_Curve25519_Field64.krml obj/Hacl_Impl_Curve25519_Fields_Core.krml obj/Hacl_Impl_Curve25519_Field51.krml obj/Hacl_Impl_Ed25519_Field51.krml obj/Hacl_Spec_Curve25519_Finv.krml obj/Hacl_Impl_Curve25519_Field64.krml obj/Hacl_Impl_Curve25519_Fields.krml obj/FStar_List_Pure_Base.krml obj/FStar_List_Pure_Properties.krml obj/FStar_List_Pure.krml obj/Meta_Interface.krml obj/Hacl_Spec_Curve25519_AddAndDouble.krml obj/Hacl_Impl_Curve25519_AddAndDouble.krml obj/Hacl_Impl_Curve25519_Finv.krml obj/Hacl_Impl_Curve25519_Generic.krml obj/Hacl_Meta_Curve25519.krml obj/Hacl_Curve25519_51.krml obj/Hacl_Curve25519_Finv_Field51.krml obj/Hacl_Bignum25519.krml obj/Hacl_Impl_Ed25519_PointAdd.krml obj/Hacl_Impl_Ed25519_PointDouble.krml obj/Lib_IntTypes_Compatibility.krml obj/Hacl_Impl_Ed25519_SwapConditional.krml obj/Hacl_Impl_Ed25519_Ladder.krml obj/Hacl_Impl_Ed25519_PointCompress.krml obj/Hacl_Impl_Ed25519_SecretExpand.krml obj/Hacl_Impl_Ed25519_SecretToPublic.krml obj/Hacl_Spec_BignumQ_Definitions.krml obj/Hacl_Spec_BignumQ_Lemmas.krml obj/Hacl_Spec_BignumQ_Mul.krml obj/Hacl_Impl_BignumQ_Mul.krml obj/Hacl_Impl_Load56.krml obj/Hacl_Impl_Store56.krml obj/Hacl_Impl_SHA512_ModQ.krml obj/Hacl_Impl_Ed25519_Sign_Steps.krml obj/Hacl_Impl_Ed25519_Sign.krml obj/Hacl_Impl_Ed25519_Sign_Expanded.krml obj/Vale_AES_X64_AESopt2.krml obj/Vale_AES_X64_AESGCM_expected_code.krml obj/Spec_Poly1305.krml obj/Hacl_Spec_Poly1305_Vec.krml obj/Hacl_Spec_Poly1305_Field32xN.krml obj/Hacl_Poly1305_Field32xN_Lemmas.krml obj/MerkleTree_Spec.krml obj/Hacl_Impl_Poly1305_Lemmas.krml obj/Hacl_Spec_Poly1305_Field32xN_Lemmas.krml obj/Hacl_Impl_Poly1305_Field32xN.krml obj/Hacl_Spec_Poly1305_Lemmas.krml obj/Hacl_Spec_Poly1305_Equiv.krml obj/Hacl_Impl_Poly1305_Field32xN_256.krml obj/Hacl_Impl_Poly1305_Field32xN_128.krml obj/Hacl_Impl_Poly1305_Field32xN_32.krml obj/Hacl_Impl_Poly1305_Fields.krml obj/Hacl_Impl_Poly1305.krml obj/Spec_Chacha20Poly1305.krml obj/Hacl_Impl_Chacha20Poly1305_PolyCore.krml obj/Hacl_Impl_Chacha20Poly1305.krml obj/Hacl_Meta_Chacha20Poly1305.krml obj/Hacl_Meta_Chacha20_Vec.krml obj/Hacl_Chacha20_Vec256.krml obj/Hacl_Meta_Poly1305.krml obj/Hacl_Poly1305_256.krml obj/Hacl_Chacha20Poly1305_256.krml obj/Hacl_Impl_Chacha20_Core32.krml obj/Hacl_Impl_Chacha20.krml obj/Hacl_Chacha20.krml obj/Hacl_Poly1305_32.krml obj/Hacl_Chacha20Poly1305_32.krml obj/FStar_Dyn.krml obj/EverCrypt_Vale.krml obj/EverCrypt_Specs.krml obj/EverCrypt_OpenSSL.krml obj/EverCrypt_Hacl.krml obj/EverCrypt_BCrypt.krml obj/EverCrypt_Cipher.krml obj/Vale_Stdcalls_X64_Fswap.krml obj/Vale_Wrapper_X64_Fswap.krml obj/Vale_X64_Print_Inline_s.krml obj/Vale_Inline_X64_Fswap_inline.krml obj/Vale_Stdcalls_X64_Fsqr.krml obj/Vale_Wrapper_X64_Fsqr.krml obj/Vale_Inline_X64_Fsqr_inline.krml obj/Vale_Stdcalls_X64_Fmul.krml obj/Vale_Wrapper_X64_Fmul.krml obj/Vale_Inline_X64_Fmul_inline.krml obj/Vale_Stdcalls_X64_Fsub.krml obj/Vale_Wrapper_X64_Fsub.krml obj/Vale_Inline_X64_Fadd_inline.krml obj/Hacl_Impl_Curve25519_Field64_Vale.krml obj/Hacl_Curve25519_64.krml obj/EverCrypt_Curve25519.krml obj/Hacl_Poly1305_128.krml obj/Vale_Poly1305_Equiv.krml obj/Vale_Poly1305_CallingFromLowStar.krml obj/EverCrypt_Poly1305.krml obj/Lib_Memzero.krml obj/Spec_Agile_HMAC.krml obj/Hacl_HMAC.krml obj/EverCrypt_HMAC.krml obj/Spec_HMAC_DRBG.krml obj/Hacl_HMAC_DRBG.krml obj/Lib_RandomBuffer_System.krml obj/EverCrypt_DRBG.krml obj/Spec_Agile_HKDF.krml obj/Hacl_HKDF.krml obj/EverCrypt_HKDF.krml obj/EverCrypt.krml obj/Spec_Salsa20.krml obj/Spec_SecretBox.krml obj/Spec_SecretBox_Test.krml obj/Vale_AES_X64_GHash.krml obj/Vale_AES_X64_AESCTR.krml obj/Vale_AES_X64_AESCTRplain.krml obj/Hacl_Impl_Salsa20_Core32.krml obj/Hacl_Impl_Salsa20.krml obj/Hacl_Impl_HSalsa20.krml obj/Hacl_Salsa20.krml obj/Vale_AES_Gcm_simplify.krml obj/Vale_AES_GCM_s.krml obj/Vale_Transformers_BoundedInstructionEffects.krml obj/Vale_Transformers_InstructionReorder.krml obj/Vale_Transformers_Transform.krml obj/Vale_AES_X64_AESopt.krml obj/Vale_AES_X64_AESGCM.krml obj/Vale_AES_X64_GCTR.krml obj/Vale_AES_GCM.krml obj/Vale_AES_X64_GCMencryptOpt.krml obj/Vale_AES_X64_GCMdecryptOpt.krml obj/Vale_Stdcalls_X64_GCMdecryptOpt.krml obj/Vale_Stdcalls_X64_Aes.krml obj/Vale_Wrapper_X64_AES.krml obj/Vale_Wrapper_X64_GCMdecryptOpt.krml obj/Vale_Wrapper_X64_GCMdecryptOpt256.krml obj/Hacl_Chacha20_Vec128.krml obj/Hacl_Chacha20Poly1305_128.krml obj/EverCrypt_Chacha20Poly1305.krml obj/Vale_Stdcalls_X64_GCM_IV.krml obj/Vale_Wrapper_X64_GCM_IV.krml obj/Vale_Stdcalls_X64_GCMencryptOpt.krml obj/Vale_Wrapper_X64_GCMencryptOpt.krml obj/Vale_Wrapper_X64_GCMencryptOpt256.krml obj/Vale_Stdcalls_X64_AesHash.krml obj/Vale_Wrapper_X64_AEShash.krml obj/Spec_Agile_Cipher.krml obj/Spec_Cipher_Expansion.krml obj/EverCrypt_CTR_Keys.krml obj/Spec_Agile_AEAD.krml obj/EverCrypt_Error.krml obj/EverCrypt_AEAD.krml obj/WasmSupport.krml obj/Lib_RandomSequence.krml obj/Vale_Transformers_InstructionReorderSanityChecks.krml obj/Spec_SHA3.krml obj/Hacl_Impl_SHA3.krml obj/LowStar_Vector.krml obj/LowStar_Regional.krml obj/LowStar_RVector.krml obj/LowStar_Regional_Instances.krml obj/Hacl_AES128.krml obj/TestLib.krml obj/MerkleTree_New_High.krml obj/MerkleTree_New_Low.krml obj/Spec_Frodo_Random.krml obj/Spec_Frodo_Lemmas.krml obj/Spec_Matrix.krml obj/Spec_Frodo_Gen.krml obj/Frodo_Params.krml obj/Spec_Frodo_Sample.krml obj/Spec_Frodo_Pack.krml obj/Spec_Frodo_Params.krml obj/Spec_Frodo_Encode.krml obj/Spec_Frodo_KEM_Encaps.krml obj/Hacl_SHA3.krml obj/Hacl_Keccak.krml obj/Hacl_Impl_Matrix.krml obj/Hacl_Impl_Frodo_Gen.krml obj/Hacl_Impl_Ed25519_Pow2_252m2.krml obj/Hacl_Impl_Ed25519_RecoverX.krml obj/Hacl_Impl_Ed25519_PointDecompress.krml obj/Hacl_Impl_Ed25519_PointEqual.krml obj/Hacl_Impl_Ed25519_Verify.krml obj/Hacl_Ed25519.krml obj/Lib_PrintBuffer.krml obj/Hacl_Test_Ed25519.krml obj/Spec_Frodo_KEM_Decaps.krml obj/Spec_Frodo_KEM_KeyGen.krml obj/Spec_Frodo_Test.krml obj/Spec_Frodo_KEM.krml obj/EverCrypt_Hash_Incremental.krml obj/Test_Vectors_Chacha20Poly1305.krml obj/Hacl_Impl_Frodo_Params.krml obj/Hacl_Impl_Frodo_Sample.krml obj/Spec_HMAC_DRBG_Test.krml obj/Vale_Test_X64_Args.krml obj/LowStar_Printf.krml obj/Vale_Test_X64_Vale_memcpy.krml obj/MerkleTree_New_High_Correct_Base.krml obj/MerkleTree_New_High_Correct_Flushing.krml obj/MerkleTree_New_High_Correct_Rhs.krml obj/Test_Vectors_Curve25519.krml obj/Spec_Box.krml obj/Hacl_Impl_SecretBox.krml obj/Hacl_Impl_Box.krml obj/Hacl_NaCl.krml obj/Vale_Test_X64_Memcpy.krml obj/Hacl_Impl_Curve25519_Field64_Hacl.krml obj/Hacl_Curve25519_64_Slow.krml obj/Test_Lowstarize.krml obj/Hacl_Test_HMAC_DRBG.krml obj/Vale_Math_Poly2_Galois_IntTypes.krml obj/Vale_Math_Poly2_Galois.krml obj/Vale_Math_Poly2_Galois_Lemmas.krml obj/Lib_RawBuffer.krml obj/Vale_Lib_MapTree.krml obj/Test_Vectors_Poly1305.krml obj/Vale_X64_Leakage_s.krml obj/Vale_X64_Leakage_Helpers.krml obj/Vale_X64_Leakage_Ins.krml obj/Vale_X64_Leakage.krml obj/Test_Vectors.krml obj/Spec_Agile_CTR.krml obj/Lib_PrintSequence.krml obj/Spec_Curve25519_Test.krml obj/Spec_Chacha20_Test.krml obj/Hacl_Impl_Frodo_Pack.krml obj/Vale_Lib_Operator.krml obj/MerkleTree_New_Low_Serialization.krml obj/Hacl_Frodo_Random.krml obj/Hacl_Impl_Frodo_KEM.krml obj/Hacl_Impl_Frodo_KEM_KeyGen.krml obj/Test_Hash.krml obj/MerkleTree_New_High_Correct_Path.krml obj/MerkleTree_New_High_Correct_Insertion.krml obj/MerkleTree_New_High_Correct.krml obj/Hacl_Impl_Curve25519_Field64_Local.krml obj/Hacl_Test_CSHAKE.krml obj/Spec_Hash_Test.krml obj/Vale_Stdcalls_X64_GCTR.krml obj/Vale_Wrapper_X64_GCTR.krml obj/Vale_Bignum_Lemmas.krml obj/Hacl_Impl_Frodo_Encode.krml obj/Hacl_Impl_Frodo_KEM_Encaps.krml obj/Hacl_Impl_Frodo_KEM_Decaps.krml obj/Hacl_Frodo_KEM.krml obj/Test_Vectors_Aes128.krml obj/Hacl_Curve25519_64_Local.krml obj/Hacl_Hash_Agile.krml obj/EverCrypt_Ed25519.krml obj/Hacl_Chacha20_Vec32.krml obj/Vale_X64_Xmms.krml obj/Hacl_Test_SHA3.krml obj/Spec_Chacha20Poly1305_Test.krml obj/Spec_Salsa20_Test.krml obj/Vale_Transformers_DebugPrint.krml obj/Vale_Lib_Lists.krml obj/Vale_FDefMulx_X64.krml obj/Vale_AsLowStar_Test.krml obj/Spec_SHA3_Test.krml obj/EverCrypt_CTR.krml obj/Test_NoHeap.krml obj/Test_Vectors_Aes128Gcm.krml obj/Spec_Box_Test.krml obj/Vale_X64_Bytes_Semantics.krml obj/Test.krml -silent -ccopt -Wno-unused -warn-error @4-6 -fparentheses Hacl_AES.c Lib_RandomBuffer_System.c Lib_Memzero.c Lib_PrintBuffer.c evercrypt_vale_stubs.c -o libevercrypt.a
  F* version: 946ec3ee
  KreMLin version: 88253438
 */

#include "MerkleTree.h"

uint32_t hash_size = (uint32_t)32U;

static uint8_t *hash_r_alloc()
{
  KRML_CHECK_SIZE(sizeof (uint8_t), hash_size);
  uint8_t *buf = KRML_HOST_CALLOC(hash_size, sizeof (uint8_t));
  return buf;
}

void hash_r_free(uint8_t *v1)
{
  KRML_HOST_FREE(v1);
}

void hash_copy(uint8_t *src, uint8_t *dst)
{
  memcpy(dst, src, hash_size * sizeof src[0U]);
}

#define LowStar_RVector_Cpy 0

typedef uint8_t LowStar_RVector_copyable__uint8_t__tags;

typedef void (*LowStar_RVector_copyable__uint8_t_)(uint8_t *x0, uint8_t *x1);

static void (*hcpy)(uint8_t *x0, uint8_t *x1) = hash_copy;

static LowStar_Vector_vector_str__uint8_t_
hash_vec_dummy = { .sz = (uint32_t)0U, .cap = (uint32_t)0U, .vs = NULL };

typedef struct LowStar_Regional_regional__uint8_t__s
{
  uint8_t *dummy;
  uint8_t *(*r_alloc)();
  void (*r_free)(uint8_t *x0);
}
LowStar_Regional_regional__uint8_t_;

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_alloc_reserve__uint8_t_(uint32_t len, uint8_t *ia)
{
  KRML_CHECK_SIZE(sizeof (uint8_t *), len);
  uint8_t **buf = KRML_HOST_MALLOC(sizeof (uint8_t *) * len);
  for (uint32_t _i = 0U; _i < len; ++_i)
    buf[_i] = ia;
  return ((LowStar_Vector_vector_str__uint8_t_){ .sz = (uint32_t)0U, .cap = len, .vs = buf });
}

static LowStar_Vector_vector_str__uint8_t_ hash_vec_r_alloc()
{
  LowStar_Regional_regional__uint8_t_
  x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  uint8_t *ia1 = x0.dummy;
  return LowStar_Vector_alloc_reserve__uint8_t_((uint32_t)1U, ia1);
}

static uint8_t
*LowStar_Vector_index__uint8_t_(LowStar_Vector_vector_str__uint8_t_ vec, uint32_t i1)
{
  return vec.vs[i1];
}

static void
LowStar_RVector_free_elems__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t idx
)
{
  uint8_t *uu____0 = LowStar_Vector_index__uint8_t_(rv, idx);
  rg.r_free(uu____0);
  if (idx != (uint32_t)0U)
  {
    LowStar_RVector_free_elems__uint8_t_(rg, rv, idx - (uint32_t)1U);
  }
}

static void LowStar_Vector_free__uint8_t_(LowStar_Vector_vector_str__uint8_t_ vec)
{
  KRML_HOST_FREE(vec.vs);
}

static void
LowStar_RVector_free__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv
)
{
  if (!(rv.sz == (uint32_t)0U))
  {
    LowStar_RVector_free_elems__uint8_t_(rg, rv, rv.sz - (uint32_t)1U);
  }
  LowStar_Vector_free__uint8_t_(rv);
}

void hash_vec_r_free(LowStar_Vector_vector_str__uint8_t_ v1)
{
  LowStar_RVector_free__uint8_t_((
      (LowStar_Regional_regional__uint8_t_){
        .dummy = NULL,
        .r_alloc = hash_r_alloc,
        .r_free = hash_r_free
      }
    ),
    v1);
}

uint8_t *(*init_hash)() = hash_r_alloc;

void (*free_hash)(uint8_t *x0) = hash_r_free;

void hash_2(uint8_t *src1, uint8_t *src2, uint8_t *dst)
{
  uint8_t cb[64U] = { 0U };
  memcpy(cb, src1, hash_size * sizeof src1[0U]);
  memcpy(cb + (uint32_t)32U, src2, hash_size * sizeof src2[0U]);
  uint32_t buf[8U] = { 0U };
  EverCrypt_Hash_state_s s = { .tag = EverCrypt_Hash_SHA2_256_s, { .case_SHA2_256_s = buf } };
  EverCrypt_Hash_state_s st = s;
  EverCrypt_Hash_init(&st);
  EverCrypt_Hash_update(&st, cb);
  EverCrypt_Hash_finish(&st, dst);
}

uint32_t uint32_32_max = (uint32_t)4294967295U;

uint64_t uint32_max = (uint64_t)4294967295U;

uint64_t uint64_max = (uint64_t)18446744073709551615U;

uint64_t offset_range_limit = (uint64_t)4294967295U;

uint32_t merkle_tree_size_lg = (uint32_t)32U;

bool uu___is_MT(merkle_tree projectee)
{
  return true;
}

uint64_t __proj__MT__item__offset(merkle_tree projectee)
{
  return projectee.offset;
}

uint32_t __proj__MT__item__i(merkle_tree projectee)
{
  return projectee.i;
}

uint32_t __proj__MT__item__j(merkle_tree projectee)
{
  return projectee.j;
}

LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
__proj__MT__item__hs(merkle_tree projectee)
{
  return projectee.hs;
}

bool __proj__MT__item__rhs_ok(merkle_tree projectee)
{
  return projectee.rhs_ok;
}

LowStar_Vector_vector_str__uint8_t_ __proj__MT__item__rhs(merkle_tree projectee)
{
  return projectee.rhs;
}

uint8_t *__proj__MT__item__mroot(merkle_tree projectee)
{
  return projectee.mroot;
}

bool
merkle_tree_conditions(
  uint64_t offset1,
  uint32_t i1,
  uint32_t j1,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs,
  bool rhs_ok,
  LowStar_Vector_vector_str__uint8_t_ rhs,
  uint8_t *mroot
)
{
  return
    j1
    >= i1
    && uint64_max - offset1 >= (uint64_t)j1
    && hs.sz == (uint32_t)32U
    && rhs.sz == (uint32_t)32U;
}

uint32_t offset_of(uint32_t i1)
{
  if (i1 % (uint32_t)2U == (uint32_t)0U)
  {
    return i1;
  }
  else
  {
    return i1 - (uint32_t)1U;
  }
}

static LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_alloc_rid__LowStar_Vector_vector_str_uint8_t_(
  uint32_t len,
  LowStar_Vector_vector_str__uint8_t_ v1
)
{
  KRML_CHECK_SIZE(sizeof (LowStar_Vector_vector_str__uint8_t_), len);
  LowStar_Vector_vector_str__uint8_t_
  *buf = KRML_HOST_MALLOC(sizeof (LowStar_Vector_vector_str__uint8_t_) * len);
  for (uint32_t _i = 0U; _i < len; ++_i)
    buf[_i] = v1;
  return
    (
      (LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_){
        .sz = len,
        .cap = len,
        .vs = buf
      }
    );
}

typedef struct LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t__s
{
  LowStar_Vector_vector_str__uint8_t_ dummy;
  LowStar_Vector_vector_str__uint8_t_ (*r_alloc)();
  void (*r_free)(LowStar_Vector_vector_str__uint8_t_ x0);
}
LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_;

static void
LowStar_Vector_assign__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ vec,
  uint32_t i1,
  LowStar_Vector_vector_str__uint8_t_ v1
)
{
  (vec.vs + i1)[0U] = v1;
}

static void
LowStar_RVector_alloc___LowStar_Vector_vector_str_uint8_t_(
  LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_ rg,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t cidx
)
{
  if (!(cidx == (uint32_t)0U))
  {
    LowStar_Vector_vector_str__uint8_t_ v1 = rg.r_alloc();
    LowStar_Vector_assign__LowStar_Vector_vector_str_uint8_t_(rv, cidx - (uint32_t)1U, v1);
    LowStar_RVector_alloc___LowStar_Vector_vector_str_uint8_t_(rg, rv, cidx - (uint32_t)1U);
  }
}

static LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
LowStar_RVector_alloc_rid__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_ rg,
  uint32_t len
)
{
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
  vec = LowStar_Vector_alloc_rid__LowStar_Vector_vector_str_uint8_t_(len, rg.dummy);
  LowStar_RVector_alloc___LowStar_Vector_vector_str_uint8_t_(rg, vec, len);
  return vec;
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_alloc_rid__uint8_t_(uint32_t len, uint8_t *v1)
{
  KRML_CHECK_SIZE(sizeof (uint8_t *), len);
  uint8_t **buf = KRML_HOST_MALLOC(sizeof (uint8_t *) * len);
  for (uint32_t _i = 0U; _i < len; ++_i)
    buf[_i] = v1;
  return ((LowStar_Vector_vector_str__uint8_t_){ .sz = len, .cap = len, .vs = buf });
}

static void
LowStar_Vector_assign__uint8_t_(
  LowStar_Vector_vector_str__uint8_t_ vec,
  uint32_t i1,
  uint8_t *v1
)
{
  (vec.vs + i1)[0U] = v1;
}

static void
LowStar_RVector_alloc___uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t cidx
)
{
  if (!(cidx == (uint32_t)0U))
  {
    uint8_t *v1 = rg.r_alloc();
    LowStar_Vector_assign__uint8_t_(rv, cidx - (uint32_t)1U, v1);
    LowStar_RVector_alloc___uint8_t_(rg, rv, cidx - (uint32_t)1U);
  }
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_RVector_alloc_rid__uint8_t_(LowStar_Regional_regional__uint8_t_ rg, uint32_t len)
{
  LowStar_Vector_vector_str__uint8_t_ vec = LowStar_Vector_alloc_rid__uint8_t_(len, rg.dummy);
  LowStar_RVector_alloc___uint8_t_(rg, vec, len);
  return vec;
}

static merkle_tree *create_empty_mt()
{
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
  hs =
    LowStar_RVector_alloc_rid__LowStar_Vector_vector_str_uint8_t_((
        (LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_){
          .dummy = hash_vec_dummy,
          .r_alloc = hash_vec_r_alloc,
          .r_free = hash_vec_r_free
        }
      ),
      (uint32_t)32U);
  LowStar_Vector_vector_str__uint8_t_
  rhs =
    LowStar_RVector_alloc_rid__uint8_t_((
        (LowStar_Regional_regional__uint8_t_){
          .dummy = NULL,
          .r_alloc = hash_r_alloc,
          .r_free = hash_r_free
        }
      ),
      (uint32_t)32U);
  LowStar_Regional_regional__uint8_t_
  x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  uint8_t *mroot = x0.r_alloc();
  KRML_CHECK_SIZE(sizeof (merkle_tree), (uint32_t)1U);
  merkle_tree *mt = KRML_HOST_MALLOC(sizeof (merkle_tree));
  mt[0U]
  =
    (
      (merkle_tree){
        .offset = (uint64_t)0U,
        .i = (uint32_t)0U,
        .j = (uint32_t)0U,
        .hs = hs,
        .rhs_ok = false,
        .rhs = rhs,
        .mroot = mroot
      }
    );
  return mt;
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ vec,
  uint32_t i1
)
{
  return vec.vs[i1];
}

static void
LowStar_RVector_free_elems__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_ rg,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t idx
)
{
  LowStar_Vector_vector_str__uint8_t_
  uu____0 = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(rv, idx);
  rg.r_free(uu____0);
  if (idx != (uint32_t)0U)
  {
    LowStar_RVector_free_elems__LowStar_Vector_vector_str_uint8_t_(rg, rv, idx - (uint32_t)1U);
  }
}

static void
LowStar_Vector_free__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ vec
)
{
  KRML_HOST_FREE(vec.vs);
}

static void
LowStar_RVector_free__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_ rg,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ rv
)
{
  if (!(rv.sz == (uint32_t)0U))
  {
    LowStar_RVector_free_elems__LowStar_Vector_vector_str_uint8_t_(rg, rv, rv.sz - (uint32_t)1U);
  }
  LowStar_Vector_free__LowStar_Vector_vector_str_uint8_t_(rv);
}

void mt_free(merkle_tree *mt)
{
  merkle_tree mtv = *mt;
  LowStar_RVector_free__LowStar_Vector_vector_str_uint8_t_((
      (LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_){
        .dummy = hash_vec_dummy,
        .r_alloc = hash_vec_r_alloc,
        .r_free = hash_vec_r_free
      }
    ),
    mtv.hs);
  LowStar_RVector_free__uint8_t_((
      (LowStar_Regional_regional__uint8_t_){
        .dummy = NULL,
        .r_alloc = hash_r_alloc,
        .r_free = hash_r_free
      }
    ),
    mtv.rhs);
  LowStar_Regional_regional__uint8_t_
  x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  x0.r_free(mtv.mroot);
  KRML_HOST_FREE(mt);
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_insert__uint8_t_(LowStar_Vector_vector_str__uint8_t_ vec, uint8_t *v1)
{
  uint32_t sz = vec.sz;
  uint32_t cap = vec.cap;
  uint8_t **vs = vec.vs;
  if (sz == cap)
  {
    uint32_t ncap = LowStar_Vector_new_capacity(cap);
    KRML_CHECK_SIZE(sizeof (uint8_t *), ncap);
    uint8_t **nvs = KRML_HOST_MALLOC(sizeof (uint8_t *) * ncap);
    for (uint32_t _i = 0U; _i < ncap; ++_i)
      nvs[_i] = v1;
    memcpy(nvs, vs, sz * sizeof vs[0U]);
    nvs[sz] = v1;
    KRML_HOST_FREE(vs);
    return
      ((LowStar_Vector_vector_str__uint8_t_){ .sz = sz + (uint32_t)1U, .cap = ncap, .vs = nvs });
  }
  else
  {
    vs[sz] = v1;
    return
      ((LowStar_Vector_vector_str__uint8_t_){ .sz = sz + (uint32_t)1U, .cap = cap, .vs = vs });
  }
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_RVector_insert__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint8_t *v1
)
{
  LowStar_Vector_vector_str__uint8_t_ irv = LowStar_Vector_insert__uint8_t_(rv, v1);
  return irv;
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_RVector_insert_copy__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  void (*cp)(uint8_t *x0, uint8_t *x1),
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint8_t *v1
)
{
  uint8_t *nv = rg.r_alloc();
  void (*copy)(uint8_t *x0, uint8_t *x1) = cp;
  copy(v1, nv);
  return LowStar_RVector_insert__uint8_t_(rg, rv, nv);
}

static void
LowStar_RVector_assign__LowStar_Vector_vector_str_uint8_t_(
  LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_ rg,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t i1,
  LowStar_Vector_vector_str__uint8_t_ v1
)
{
  LowStar_Vector_assign__LowStar_Vector_vector_str_uint8_t_(rv, i1, v1);
}

static void
insert_(
  uint32_t lv,
  uint32_t j1,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs,
  uint8_t *acc
)
{
  LowStar_Vector_vector_str__uint8_t_
  uu____0 = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs, lv);
  LowStar_Vector_vector_str__uint8_t_
  ihv =
    LowStar_RVector_insert_copy__uint8_t_((
        (LowStar_Regional_regional__uint8_t_){
          .dummy = NULL,
          .r_alloc = hash_r_alloc,
          .r_free = hash_r_free
        }
      ),
      hcpy,
      uu____0,
      acc);
  LowStar_RVector_assign__LowStar_Vector_vector_str_uint8_t_((
      (LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_){
        .dummy = hash_vec_dummy,
        .r_alloc = hash_vec_r_alloc,
        .r_free = hash_vec_r_free
      }
    ),
    hs,
    lv,
    ihv);
  if (j1 % (uint32_t)2U == (uint32_t)1U)
  {
    LowStar_Vector_vector_str__uint8_t_
    lvhs = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs, lv);
    hash_2(LowStar_Vector_index__uint8_t_(lvhs, lvhs.sz - (uint32_t)2U), acc, acc);
    insert_(lv + (uint32_t)1U, j1 / (uint32_t)2U, hs, acc);
  }
}

bool mt_insert_pre(merkle_tree *mt, uint8_t *v1)
{
  merkle_tree uu____0 = *mt;
  return
    uu____0.j
    < uint32_32_max
    && uint64_max - uu____0.offset >= (uint64_t)(uu____0.j + (uint32_t)1U);
}

void mt_insert(merkle_tree *mt, uint8_t *v1)
{
  merkle_tree mtv = *mt;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = mtv.hs;
  insert_((uint32_t)0U, mtv.j, hs, v1);
  *mt
  =
    (
      (merkle_tree){
        .offset = mtv.offset,
        .i = mtv.i,
        .j = mtv.j + (uint32_t)1U,
        .hs = mtv.hs,
        .rhs_ok = false,
        .rhs = mtv.rhs,
        .mroot = mtv.mroot
      }
    );
}

merkle_tree *mt_create(uint8_t *init1)
{
  merkle_tree *mt = create_empty_mt();
  mt_insert(mt, init1);
  return mt;
}

LowStar_Vector_vector_str__uint8_t_ *init_path()
{
  KRML_CHECK_SIZE(sizeof (LowStar_Vector_vector_str__uint8_t_), (uint32_t)1U);
  LowStar_Vector_vector_str__uint8_t_
  *buf = KRML_HOST_MALLOC(sizeof (LowStar_Vector_vector_str__uint8_t_));
  buf[0U] = hash_vec_r_alloc();
  return buf;
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_clear__uint8_t_(LowStar_Vector_vector_str__uint8_t_ vec)
{
  return
    ((LowStar_Vector_vector_str__uint8_t_){ .sz = (uint32_t)0U, .cap = vec.cap, .vs = vec.vs });
}

void clear_path(LowStar_Vector_vector_str__uint8_t_ *p1)
{
  *p1 = LowStar_Vector_clear__uint8_t_(*p1);
}

void free_path(LowStar_Vector_vector_str__uint8_t_ *p1)
{
  LowStar_Vector_free__uint8_t_(*p1);
  KRML_HOST_FREE(p1);
}

static void
LowStar_RVector_assign_copy__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  void (*cp)(uint8_t *x0, uint8_t *x1),
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t i1,
  uint8_t *v1
)
{
  void (*copy)(uint8_t *x0, uint8_t *x1) = cp;
  copy(v1, LowStar_Vector_index__uint8_t_(rv, i1));
}

static void
construct_rhs(
  uint32_t lv,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs,
  LowStar_Vector_vector_str__uint8_t_ rhs,
  uint32_t i1,
  uint32_t j1,
  uint8_t *acc,
  bool actd
)
{
  uint32_t ofs = offset_of(i1);
  LowStar_Regional_regional__uint8_t_
  x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  void (*copy1)(uint8_t *x0, uint8_t *x1) = hcpy;
  if (!(j1 == (uint32_t)0U))
  {
    if (j1 % (uint32_t)2U == (uint32_t)0U)
    {
      construct_rhs(lv + (uint32_t)1U, hs, rhs, i1 / (uint32_t)2U, j1 / (uint32_t)2U, acc, actd);
    }
    else
    {
      if (actd)
      {
        LowStar_RVector_assign_copy__uint8_t_((
            (LowStar_Regional_regional__uint8_t_){
              .dummy = NULL,
              .r_alloc = hash_r_alloc,
              .r_free = hash_r_free
            }
          ),
          hcpy,
          rhs,
          lv,
          acc);
        hash_2(LowStar_Vector_index__uint8_t_(LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs,
              lv),
            j1 - (uint32_t)1U - ofs),
          acc,
          acc);
      }
      else
      {
        copy1(LowStar_Vector_index__uint8_t_(LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs,
              lv),
            j1 - (uint32_t)1U - ofs),
          acc);
      }
      construct_rhs(lv + (uint32_t)1U, hs, rhs, i1 / (uint32_t)2U, j1 / (uint32_t)2U, acc, true);
    }
  }
}

bool mt_get_root_pre(merkle_tree *mt, uint8_t *rt)
{
  merkle_tree uu____0 = *mt;
  return true;
}

void mt_get_root(merkle_tree *mt, uint8_t *rt)
{
  merkle_tree mtv = *mt;
  uint64_t prefix = mtv.offset;
  uint32_t i1 = mtv.i;
  uint32_t j1 = mtv.j;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = mtv.hs;
  LowStar_Vector_vector_str__uint8_t_ rhs = mtv.rhs;
  uint8_t *mroot = mtv.mroot;
  if (mtv.rhs_ok)
  {
    LowStar_Regional_regional__uint8_t_
    x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
    hcpy(mroot, rt);
  }
  else
  {
    construct_rhs((uint32_t)0U, hs, rhs, i1, j1, rt, false);
    LowStar_Regional_regional__uint8_t_
    x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
    hcpy(rt, mroot);
    *mt
    =
      (
        (merkle_tree){
          .offset = prefix,
          .i = i1,
          .j = j1,
          .hs = hs,
          .rhs_ok = true,
          .rhs = rhs,
          .mroot = mroot
        }
      );
  }
}

void path_insert(LowStar_Vector_vector_str__uint8_t_ *p1, uint8_t *hp)
{
  LowStar_Vector_vector_str__uint8_t_ pv = p1[0U];
  LowStar_Vector_vector_str__uint8_t_ ipv = LowStar_Vector_insert__uint8_t_(pv, hp);
  *p1 = ipv;
}

static uint32_t mt_path_length_step(uint32_t k1, uint32_t j1, bool actd)
{
  if (j1 == (uint32_t)0U)
  {
    return (uint32_t)0U;
  }
  else if (k1 % (uint32_t)2U == (uint32_t)0U)
  {
    if (j1 == k1 || (j1 == k1 + (uint32_t)1U && !actd))
    {
      return (uint32_t)0U;
    }
    else
    {
      return (uint32_t)1U;
    }
  }
  else
  {
    return (uint32_t)1U;
  }
}

static uint32_t mt_path_length(uint32_t lv, uint32_t k1, uint32_t j1, bool actd)
{
  if (j1 == (uint32_t)0U)
  {
    return (uint32_t)0U;
  }
  else
  {
    bool nactd = actd || j1 % (uint32_t)2U == (uint32_t)1U;
    return
      mt_path_length_step(k1,
        j1,
        actd)
      + mt_path_length(lv + (uint32_t)1U, k1 / (uint32_t)2U, j1 / (uint32_t)2U, nactd);
  }
}

static void
mt_get_path_(
  uint32_t lv,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs,
  LowStar_Vector_vector_str__uint8_t_ rhs,
  uint32_t i1,
  uint32_t j1,
  uint32_t k1,
  LowStar_Vector_vector_str__uint8_t_ *p1,
  bool actd
)
{
  uint32_t ofs = offset_of(i1);
  if (!(j1 == (uint32_t)0U))
  {
    uint32_t ofs1 = offset_of(i1);
    if (k1 % (uint32_t)2U == (uint32_t)1U)
    {
      uint8_t
      *uu____0 =
        LowStar_Vector_index__uint8_t_(LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs,
            lv),
          k1 - (uint32_t)1U - ofs1);
      LowStar_Vector_vector_str__uint8_t_ pv = p1[0U];
      LowStar_Vector_vector_str__uint8_t_ ipv = LowStar_Vector_insert__uint8_t_(pv, uu____0);
      *p1 = ipv;
    }
    else if (!(k1 == j1))
    {
      if (k1 + (uint32_t)1U == j1)
      {
        if (actd)
        {
          uint8_t *uu____1 = LowStar_Vector_index__uint8_t_(rhs, lv);
          LowStar_Vector_vector_str__uint8_t_ pv = p1[0U];
          LowStar_Vector_vector_str__uint8_t_ ipv = LowStar_Vector_insert__uint8_t_(pv, uu____1);
          *p1 = ipv;
        }
      }
      else
      {
        uint8_t
        *uu____2 =
          LowStar_Vector_index__uint8_t_(LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs,
              lv),
            k1 + (uint32_t)1U - ofs1);
        LowStar_Vector_vector_str__uint8_t_ pv = p1[0U];
        LowStar_Vector_vector_str__uint8_t_ ipv = LowStar_Vector_insert__uint8_t_(pv, uu____2);
        *p1 = ipv;
      }
    }
    bool ite;
    if (j1 % (uint32_t)2U == (uint32_t)0U)
    {
      ite = actd;
    }
    else
    {
      ite = true;
    }
    mt_get_path_(lv + (uint32_t)1U,
      hs,
      rhs,
      i1 / (uint32_t)2U,
      j1 / (uint32_t)2U,
      k1 / (uint32_t)2U,
      p1,
      ite);
  }
}

bool
mt_get_path_pre(
  merkle_tree *mt,
  uint64_t idx,
  LowStar_Vector_vector_str__uint8_t_ *p1,
  uint8_t *root
)
{
  merkle_tree uu____0 = *mt;
  LowStar_Vector_vector_str__uint8_t_ uu____1 = *p1;
  if (idx >= uu____0.offset && idx - uu____0.offset <= offset_range_limit)
  {
    uint64_t diff = idx - uu____0.offset;
    uint32_t idx1 = (uint32_t)diff;
    return uu____0.i <= idx1 && idx1 < uu____0.j && uu____1.sz == (uint32_t)0U;
  }
  else
  {
    return false;
  }
}

uint32_t
mt_get_path(
  merkle_tree *mt,
  uint64_t idx,
  LowStar_Vector_vector_str__uint8_t_ *p1,
  uint8_t *root
)
{
  LowStar_Regional_regional__uint8_t_
  x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  void (*copy1)(uint8_t *x0, uint8_t *x1) = hcpy;
  mt_get_root(mt, root);
  merkle_tree mtv = *mt;
  uint64_t diff = idx - mtv.offset;
  uint32_t idx1 = (uint32_t)diff;
  uint32_t i1 = mtv.i;
  uint32_t ofs = offset_of(mtv.i);
  uint32_t j1 = mtv.j;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = mtv.hs;
  LowStar_Vector_vector_str__uint8_t_ rhs = mtv.rhs;
  uint8_t
  *ih =
    LowStar_Vector_index__uint8_t_(LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs,
        (uint32_t)0U),
      idx1 - ofs);
  LowStar_Vector_vector_str__uint8_t_ pv = p1[0U];
  LowStar_Vector_vector_str__uint8_t_ ipv = LowStar_Vector_insert__uint8_t_(pv, ih);
  *p1 = ipv;
  mt_get_path_((uint32_t)0U, hs, rhs, i1, j1, idx1, p1, false);
  return j1;
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_flush__uint8_t_(
  LowStar_Vector_vector_str__uint8_t_ vec,
  uint8_t *ia,
  uint32_t i1
)
{
  uint32_t fsz = vec.sz - i1;
  uint32_t asz;
  if (vec.sz == i1)
  {
    asz = (uint32_t)1U;
  }
  else
  {
    asz = fsz;
  }
  uint8_t **vs = vec.vs;
  KRML_CHECK_SIZE(sizeof (uint8_t *), asz);
  uint8_t **fvs = KRML_HOST_MALLOC(sizeof (uint8_t *) * asz);
  for (uint32_t _i = 0U; _i < asz; ++_i)
    fvs[_i] = ia;
  memcpy(fvs, vs + i1, fsz * sizeof vs[0U]);
  KRML_HOST_FREE(vs);
  return ((LowStar_Vector_vector_str__uint8_t_){ .sz = fsz, .cap = asz, .vs = fvs });
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_RVector_flush__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t i1
)
{
  if (!(i1 == (uint32_t)0U))
  {
    LowStar_RVector_free_elems__uint8_t_(rg, rv, i1 - (uint32_t)1U);
  }
  LowStar_Vector_vector_str__uint8_t_ frv = LowStar_Vector_flush__uint8_t_(rv, rg.dummy, i1);
  return frv;
}

static void
mt_flush_to_(
  uint32_t lv,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs,
  uint32_t pi,
  uint32_t i1
)
{
  uint32_t oi = offset_of(i1);
  uint32_t opi = offset_of(pi);
  if (!(oi == opi))
  {
    uint32_t ofs = oi - opi;
    LowStar_Vector_vector_str__uint8_t_
    hvec = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs, lv);
    LowStar_Vector_vector_str__uint8_t_
    flushed =
      LowStar_RVector_flush__uint8_t_((
          (LowStar_Regional_regional__uint8_t_){
            .dummy = NULL,
            .r_alloc = hash_r_alloc,
            .r_free = hash_r_free
          }
        ),
        hvec,
        ofs);
    LowStar_RVector_assign__LowStar_Vector_vector_str_uint8_t_((
        (LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_){
          .dummy = hash_vec_dummy,
          .r_alloc = hash_vec_r_alloc,
          .r_free = hash_vec_r_free
        }
      ),
      hs,
      lv,
      flushed);
    mt_flush_to_(lv + (uint32_t)1U, hs, pi / (uint32_t)2U, i1 / (uint32_t)2U);
  }
}

bool mt_flush_to_pre(merkle_tree *mt, uint64_t idx)
{
  merkle_tree mtv = *mt;
  if (idx >= mtv.offset && idx - mtv.offset <= offset_range_limit)
  {
    uint64_t diff = idx - mtv.offset;
    uint32_t idx1 = (uint32_t)diff;
    return idx1 >= mtv.i && idx1 < mtv.j;
  }
  else
  {
    return false;
  }
}

void mt_flush_to(merkle_tree *mt, uint64_t idx)
{
  merkle_tree mtv = *mt;
  uint64_t offset1 = mtv.offset;
  uint64_t diff = idx - offset1;
  uint32_t idx1 = (uint32_t)diff;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = mtv.hs;
  mt_flush_to_((uint32_t)0U, hs, mtv.i, idx1);
  *mt
  =
    (
      (merkle_tree){
        .offset = mtv.offset,
        .i = idx1,
        .j = mtv.j,
        .hs = hs,
        .rhs_ok = mtv.rhs_ok,
        .rhs = mtv.rhs,
        .mroot = mtv.mroot
      }
    );
}

bool mt_flush_pre(merkle_tree *mt)
{
  merkle_tree uu____0 = *mt;
  return uu____0.j > uu____0.i;
}

void mt_flush(merkle_tree *mt)
{
  merkle_tree mtv = *mt;
  uint64_t off = mtv.offset;
  uint32_t j1 = mtv.j;
  uint32_t j11 = j1 - (uint32_t)1U;
  uint64_t jo = off + (uint64_t)j11;
  mt_flush_to(mt, jo);
}

static void
LowStar_RVector_free_elems_from__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t idx
)
{
  uint8_t *uu____0 = LowStar_Vector_index__uint8_t_(rv, idx);
  rg.r_free(uu____0);
  if (idx + (uint32_t)1U < rv.sz)
  {
    LowStar_RVector_free_elems_from__uint8_t_(rg, rv, idx + (uint32_t)1U);
  }
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_shrink__uint8_t_(LowStar_Vector_vector_str__uint8_t_ vec, uint32_t new_size)
{
  return ((LowStar_Vector_vector_str__uint8_t_){ .sz = new_size, .cap = vec.cap, .vs = vec.vs });
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_RVector_shrink__uint8_t_(
  LowStar_Regional_regional__uint8_t_ rg,
  LowStar_Vector_vector_str__uint8_t_ rv,
  uint32_t new_size
)
{
  uint32_t size = rv.sz;
  if (new_size >= size)
  {
    return rv;
  }
  else
  {
    LowStar_RVector_free_elems_from__uint8_t_(rg, rv, new_size);
    LowStar_Vector_vector_str__uint8_t_ frv = LowStar_Vector_shrink__uint8_t_(rv, new_size);
    return frv;
  }
}

static void
mt_retract_to_(
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs,
  uint32_t lv,
  uint32_t i1,
  uint32_t s,
  uint32_t j1
)
{
  if (!(lv >= hs.sz))
  {
    LowStar_Vector_vector_str__uint8_t_
    hvec = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(hs, lv);
    uint32_t old_len = j1 - offset_of(i1);
    uint32_t new_len = s - offset_of(i1);
    LowStar_Vector_vector_str__uint8_t_
    retracted =
      LowStar_RVector_shrink__uint8_t_((
          (LowStar_Regional_regional__uint8_t_){
            .dummy = NULL,
            .r_alloc = hash_r_alloc,
            .r_free = hash_r_free
          }
        ),
        hvec,
        new_len);
    LowStar_RVector_assign__LowStar_Vector_vector_str_uint8_t_((
        (LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_){
          .dummy = hash_vec_dummy,
          .r_alloc = hash_vec_r_alloc,
          .r_free = hash_vec_r_free
        }
      ),
      hs,
      lv,
      retracted);
    if (lv + (uint32_t)1U < hs.sz)
    {
      mt_retract_to_(hs, lv + (uint32_t)1U, i1 / (uint32_t)2U, s / (uint32_t)2U, j1 / (uint32_t)2U);
    }
  }
}

bool mt_retract_to_pre(merkle_tree *mt, uint64_t r)
{
  merkle_tree mtv = *mt;
  if (r >= mtv.offset && r - mtv.offset <= offset_range_limit)
  {
    uint64_t diff = r - mtv.offset;
    uint32_t r1 = (uint32_t)diff;
    return mtv.i <= r1 && r1 < mtv.j;
  }
  else
  {
    return false;
  }
}

void mt_retract_to(merkle_tree *mt, uint64_t r)
{
  merkle_tree mtv = *mt;
  uint64_t offset1 = mtv.offset;
  uint64_t diff = r - offset1;
  uint32_t r1 = (uint32_t)diff;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = mtv.hs;
  mt_retract_to_(hs, (uint32_t)0U, mtv.i, r1 + (uint32_t)1U, mtv.j);
  *mt
  =
    (
      (merkle_tree){
        .offset = mtv.offset,
        .i = mtv.i,
        .j = r1 + (uint32_t)1U,
        .hs = hs,
        .rhs_ok = false,
        .rhs = mtv.rhs,
        .mroot = mtv.mroot
      }
    );
}

static void
mt_verify_(
  uint32_t k1,
  uint32_t j1,
  LowStar_Vector_vector_str__uint8_t_ *p1,
  uint32_t ppos,
  uint8_t *acc,
  bool actd
)
{
  if (!(j1 == (uint32_t)0U))
  {
    bool nactd = actd || j1 % (uint32_t)2U == (uint32_t)1U;
    if (k1 % (uint32_t)2U == (uint32_t)0U)
    {
      if (j1 == k1 || (j1 == k1 + (uint32_t)1U && !actd))
      {
        mt_verify_(k1 / (uint32_t)2U, j1 / (uint32_t)2U, p1, ppos, acc, nactd);
      }
      else
      {
        uint8_t *phash = LowStar_Vector_index__uint8_t_(*p1, ppos);
        hash_2(acc, phash, acc);
        mt_verify_(k1 / (uint32_t)2U, j1 / (uint32_t)2U, p1, ppos + (uint32_t)1U, acc, nactd);
      }
    }
    else
    {
      uint8_t *phash = LowStar_Vector_index__uint8_t_(*p1, ppos);
      hash_2(phash, acc, acc);
      mt_verify_(k1 / (uint32_t)2U, j1 / (uint32_t)2U, p1, ppos + (uint32_t)1U, acc, nactd);
    }
  }
}

bool
mt_verify_pre(
  merkle_tree *mt,
  uint64_t k1,
  uint64_t j1,
  LowStar_Vector_vector_str__uint8_t_ *p1,
  uint8_t *rt
)
{
  merkle_tree uu____0 = *mt;
  LowStar_Vector_vector_str__uint8_t_ uu____1 = *p1;
  if
  (
    k1
    < j1
    && k1 >= uu____0.offset && k1 - uu____0.offset <= offset_range_limit
    && j1 >= uu____0.offset && j1 - uu____0.offset <= offset_range_limit
  )
  {
    uint64_t diff0 = k1 - uu____0.offset;
    uint32_t k2 = (uint32_t)diff0;
    uint64_t diff = j1 - uu____0.offset;
    uint32_t j2 = (uint32_t)diff;
    return uu____1.sz == (uint32_t)1U + mt_path_length((uint32_t)0U, k2, j2, false);
  }
  else
  {
    return false;
  }
}

bool
mt_verify(
  merkle_tree *mt,
  uint64_t k1,
  uint64_t j1,
  LowStar_Vector_vector_str__uint8_t_ *p1,
  uint8_t *rt
)
{
  merkle_tree mtv = *mt;
  uint64_t diff0 = k1 - mtv.offset;
  uint32_t k2 = (uint32_t)diff0;
  uint64_t diff = j1 - mtv.offset;
  uint32_t j2 = (uint32_t)diff;
  LowStar_Regional_regional__uint8_t_
  x00 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  uint8_t *ih = x00.r_alloc();
  LowStar_Regional_regional__uint8_t_
  x01 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  void (*copy1)(uint8_t *x0, uint8_t *x1) = hcpy;
  copy1(LowStar_Vector_index__uint8_t_(*p1, (uint32_t)0U), ih);
  mt_verify_(k2, j2, p1, (uint32_t)1U, ih, false);
  uint8_t res = (uint8_t)255U;
  for (uint32_t i = (uint32_t)0U; i < hash_size; i = i + (uint32_t)1U)
  {
    uint8_t uu____0 = FStar_UInt8_eq_mask(ih[i], rt[i]);
    res = uu____0 & res;
  }
  uint8_t z = res;
  bool r = z == (uint8_t)255U;
  LowStar_Regional_regional__uint8_t_
  x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
  x0.r_free(ih);
  return r;
}

typedef struct K___bool_uint32_t_s
{
  bool fst;
  uint32_t snd;
}
K___bool_uint32_t;

static K___bool_uint32_t
serialize_bool(bool ok, bool x, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    uint8_t ite;
    if (x)
    {
      ite = (uint8_t)1U;
    }
    else
    {
      ite = (uint8_t)0U;
    }
    buf1[pos] = ite;
    return ((K___bool_uint32_t){ .fst = true, .snd = pos + (uint32_t)1U });
  }
}

static K___bool_uint32_t
serialize_uint8_t(bool ok, uint8_t x, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    buf1[pos] = x;
    return ((K___bool_uint32_t){ .fst = true, .snd = pos + (uint32_t)1U });
  }
}

static K___bool_uint32_t
serialize_uint16_t(bool ok, uint16_t x, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  K___bool_uint32_t scrut = serialize_uint8_t(ok, (uint8_t)(x >> (uint32_t)8U), buf1, sz, pos);
  bool ok1 = scrut.fst;
  uint32_t pos1 = scrut.snd;
  return serialize_uint8_t(ok1, (uint8_t)x, buf1, sz, pos1);
}

static K___bool_uint32_t
serialize_uint32_t(bool ok, uint32_t x, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  K___bool_uint32_t
  scrut = serialize_uint16_t(ok, (uint16_t)(x >> (uint32_t)16U), buf1, sz, pos);
  bool ok1 = scrut.fst;
  uint32_t pos1 = scrut.snd;
  return serialize_uint16_t(ok1, (uint16_t)x, buf1, sz, pos1);
}

static K___bool_uint32_t
serialize_uint64_t(bool ok, uint64_t x, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  K___bool_uint32_t
  scrut = serialize_uint32_t(ok, (uint32_t)(x >> (uint32_t)32U), buf1, sz, pos);
  bool ok1 = scrut.fst;
  uint32_t pos1 = scrut.snd;
  return serialize_uint32_t(ok1, (uint32_t)x, buf1, sz, pos1);
}

static K___bool_uint32_t
(*serialize_offset_t)(bool x0, uint64_t x1, uint8_t *x2, uint32_t x3, uint32_t x4) =
  serialize_uint64_t;

static K___bool_uint32_t
serialize_hash_i(bool ok, uint8_t *x, uint8_t *buf1, uint32_t sz, uint32_t pos, uint32_t i1)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    uint8_t b = x[i1];
    K___bool_uint32_t scrut = serialize_uint8_t(ok, b, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    uint32_t j1 = i1 + (uint32_t)1U;
    if (j1 < hash_size)
    {
      return serialize_hash_i(ok1, x, buf1, sz, pos1, j1);
    }
    else
    {
      return ((K___bool_uint32_t){ .fst = ok1, .snd = pos1 });
    }
  }
}

static K___bool_uint32_t
serialize_hash(bool ok, uint8_t *x, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    return serialize_hash_i(ok, x, buf1, sz, pos, (uint32_t)0U);
  }
}

static K___bool_uint32_t
serialize_hash_vec_i(
  bool ok,
  LowStar_Vector_vector_str__uint8_t_ x,
  uint8_t *buf1,
  uint32_t sz,
  uint32_t pos,
  uint32_t i1
)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    uint8_t *vi = LowStar_Vector_index__uint8_t_(x, i1);
    K___bool_uint32_t scrut = serialize_hash(ok, vi, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    uint32_t j1 = i1 + (uint32_t)1U;
    if (j1 < x.sz)
    {
      return serialize_hash_vec_i(ok1, x, buf1, sz, pos1, j1);
    }
    else
    {
      return ((K___bool_uint32_t){ .fst = ok1, .snd = pos1 });
    }
  }
}

static K___bool_uint32_t
serialize_hash_vec(
  bool ok,
  LowStar_Vector_vector_str__uint8_t_ x,
  uint8_t *buf1,
  uint32_t sz,
  uint32_t pos
)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    K___bool_uint32_t scrut = serialize_uint32_t(ok, x.sz, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    if (ok1 && x.sz > (uint32_t)0U)
    {
      return serialize_hash_vec_i(ok1, x, buf1, sz, pos1, (uint32_t)0U);
    }
    else
    {
      return ((K___bool_uint32_t){ .fst = ok1, .snd = pos1 });
    }
  }
}

static uint64_t
hash_vv_bytes_i(
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ vv1,
  uint32_t i1
)
{
  if (i1 >= vv1.sz)
  {
    return (uint64_t)4U;
  }
  else
  {
    LowStar_Vector_vector_str__uint8_t_
    vvi = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(vv1, i1);
    uint64_t r = (uint64_t)4U + (uint64_t)vvi.sz * (uint64_t)hash_size;
    uint64_t rest = hash_vv_bytes_i(vv1, i1 + (uint32_t)1U);
    if (uint64_max - rest < r)
    {
      return uint64_max;
    }
    else
    {
      return rest + r;
    }
  }
}

static uint64_t
hash_vv_bytes(LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ vv1)
{
  return hash_vv_bytes_i(vv1, (uint32_t)0U);
}

static K___bool_uint32_t
serialize_hash_vv_i(
  bool ok,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ x,
  uint8_t *buf1,
  uint32_t sz,
  uint32_t pos,
  uint32_t i1
)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    LowStar_Vector_vector_str__uint8_t_
    vi = LowStar_Vector_index__LowStar_Vector_vector_str_uint8_t_(x, i1);
    K___bool_uint32_t scrut = serialize_hash_vec(ok, vi, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    uint32_t j1 = i1 + (uint32_t)1U;
    if (j1 < x.sz)
    {
      return serialize_hash_vv_i(ok1, x, buf1, sz, pos1, j1);
    }
    else
    {
      return ((K___bool_uint32_t){ .fst = ok1, .snd = pos1 });
    }
  }
}

static K___bool_uint32_t
serialize_hash_vv(
  bool ok,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ x,
  uint8_t *buf1,
  uint32_t sz,
  uint32_t pos
)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    K___bool_uint32_t scrut = serialize_uint32_t(ok, x.sz, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    if (x.sz > (uint32_t)0U)
    {
      return serialize_hash_vv_i(ok1, x, buf1, sz, pos1, (uint32_t)0U);
    }
    else
    {
      return ((K___bool_uint32_t){ .fst = ok1, .snd = pos1 });
    }
  }
}

typedef struct K___bool_uint32_t_bool_s
{
  bool fst;
  uint32_t snd;
  bool thd;
}
K___bool_uint32_t_bool;

static K___bool_uint32_t_bool
deserialize_bool(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t_bool){ .fst = false, .snd = pos, .thd = false });
  }
  else
  {
    bool sw;
    switch (buf1[pos])
    {
      case 0U:
        {
          sw = false;
          break;
        }
      default:
        {
          sw = true;
        }
    }
    return ((K___bool_uint32_t_bool){ .fst = true, .snd = pos + (uint32_t)1U, .thd = sw });
  }
}

typedef struct K___bool_uint32_t_uint8_t_s
{
  bool fst;
  uint32_t snd;
  uint8_t thd;
}
K___bool_uint32_t_uint8_t;

static K___bool_uint32_t_uint8_t
deserialize_uint8_t(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t_uint8_t){ .fst = false, .snd = pos, .thd = (uint8_t)0U });
  }
  else
  {
    return
      ((K___bool_uint32_t_uint8_t){ .fst = true, .snd = pos + (uint32_t)1U, .thd = buf1[pos] });
  }
}

typedef struct K___bool_uint32_t_uint16_t_s
{
  bool fst;
  uint32_t snd;
  uint16_t thd;
}
K___bool_uint32_t_uint16_t;

static K___bool_uint32_t_uint16_t
deserialize_uint16_t(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t_uint16_t){ .fst = false, .snd = pos, .thd = (uint16_t)0U });
  }
  else
  {
    K___bool_uint32_t_uint8_t scrut0 = deserialize_uint8_t(ok, buf1, sz, pos);
    bool ok1 = scrut0.fst;
    uint32_t pos1 = scrut0.snd;
    uint8_t b0 = scrut0.thd;
    K___bool_uint32_t_uint8_t scrut = deserialize_uint8_t(ok1, buf1, sz, pos1);
    bool ok2 = scrut.fst;
    uint32_t pos2 = scrut.snd;
    uint8_t b1 = scrut.thd;
    return
      (
        (K___bool_uint32_t_uint16_t){
          .fst = ok2,
          .snd = pos2,
          .thd = ((uint16_t)b0 << (uint32_t)8U) + (uint16_t)b1
        }
      );
  }
}

typedef struct K___bool_uint32_t_uint32_t_s
{
  bool fst;
  uint32_t snd;
  uint32_t thd;
}
K___bool_uint32_t_uint32_t;

static K___bool_uint32_t_uint32_t
deserialize_uint32_t(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t_uint32_t){ .fst = false, .snd = pos, .thd = (uint32_t)0U });
  }
  else
  {
    K___bool_uint32_t_uint16_t scrut0 = deserialize_uint16_t(ok, buf1, sz, pos);
    bool ok1 = scrut0.fst;
    uint32_t pos1 = scrut0.snd;
    uint16_t b0 = scrut0.thd;
    K___bool_uint32_t_uint16_t scrut = deserialize_uint16_t(ok1, buf1, sz, pos1);
    bool ok2 = scrut.fst;
    uint32_t pos2 = scrut.snd;
    uint16_t b1 = scrut.thd;
    return
      (
        (K___bool_uint32_t_uint32_t){
          .fst = ok2,
          .snd = pos2,
          .thd = ((uint32_t)b0 << (uint32_t)16U) + (uint32_t)b1
        }
      );
  }
}

typedef struct K___bool_uint32_t_uint64_t_s
{
  bool fst;
  uint32_t snd;
  uint64_t thd;
}
K___bool_uint32_t_uint64_t;

static K___bool_uint32_t_uint64_t
deserialize_uint64_t(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t_uint64_t){ .fst = false, .snd = pos, .thd = (uint64_t)0U });
  }
  else
  {
    K___bool_uint32_t_uint32_t scrut0 = deserialize_uint32_t(ok, buf1, sz, pos);
    bool ok1 = scrut0.fst;
    uint32_t pos1 = scrut0.snd;
    uint32_t b0 = scrut0.thd;
    K___bool_uint32_t_uint32_t scrut = deserialize_uint32_t(ok1, buf1, sz, pos1);
    bool ok2 = scrut.fst;
    uint32_t pos2 = scrut.snd;
    uint32_t b1 = scrut.thd;
    return
      (
        (K___bool_uint32_t_uint64_t){
          .fst = ok2,
          .snd = pos2,
          .thd = ((uint64_t)b0 << (uint32_t)32U) + (uint64_t)b1
        }
      );
  }
}

static K___bool_uint32_t_uint64_t
(*deserialize_offset_t)(bool x0, uint8_t *x1, uint32_t x2, uint32_t x3) = deserialize_uint64_t;

static K___bool_uint32_t_uint32_t
(*deserialize_index_t)(bool x0, uint8_t *x1, uint32_t x2, uint32_t x3) = deserialize_uint32_t;

typedef struct K___bool_uint32_t_uint8_t__s
{
  bool fst;
  uint32_t snd;
  uint8_t *thd;
}
K___bool_uint32_t_uint8_t_;

static K___bool_uint32_t_uint8_t_
deserialize_hash(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    LowStar_Regional_regional__uint8_t_
    x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
    return ((K___bool_uint32_t_uint8_t_){ .fst = false, .snd = pos, .thd = x0.dummy });
  }
  else if (sz - pos < hash_size)
  {
    LowStar_Regional_regional__uint8_t_
    x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
    return ((K___bool_uint32_t_uint8_t_){ .fst = false, .snd = pos, .thd = x0.dummy });
  }
  else
  {
    LowStar_Regional_regional__uint8_t_
    x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
    uint8_t *hash1 = x0.r_alloc();
    memcpy(hash1, buf1 + pos, hash_size * sizeof buf1[0U]);
    return ((K___bool_uint32_t_uint8_t_){ .fst = true, .snd = pos + hash_size, .thd = hash1 });
  }
}

static K___bool_uint32_t
deserialize_hash_vec_i(
  bool ok,
  uint8_t *buf1,
  uint32_t sz,
  uint32_t pos,
  LowStar_Vector_vector_str__uint8_t_ res,
  uint32_t i1
)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = pos });
  }
  else
  {
    K___bool_uint32_t_uint8_t_ scrut = deserialize_hash(ok, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    uint8_t *h1 = scrut.thd;
    if (!ok1)
    {
      return ((K___bool_uint32_t){ .fst = false, .snd = pos1 });
    }
    else
    {
      LowStar_Vector_assign__uint8_t_(res, i1, h1);
      uint32_t j1 = i1 + (uint32_t)1U;
      if (j1 < res.sz)
      {
        return deserialize_hash_vec_i(ok1, buf1, sz, pos1, res, j1);
      }
      else
      {
        return ((K___bool_uint32_t){ .fst = true, .snd = pos1 });
      }
    }
  }
}

static LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_alloc__uint8_t_(uint32_t len, uint8_t *v1)
{
  return LowStar_Vector_alloc_rid__uint8_t_(len, v1);
}

typedef struct K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t__s
{
  bool fst;
  uint32_t snd;
  LowStar_Vector_vector_str__uint8_t_ thd;
}
K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_;

static K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_
deserialize_hash_vec(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_
    scrut = { .dummy = hash_vec_dummy, .r_alloc = hash_vec_r_alloc, .r_free = hash_vec_r_free };
    return
      (
        (K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_){
          .fst = false,
          .snd = pos,
          .thd = scrut.dummy
        }
      );
  }
  else
  {
    K___bool_uint32_t_uint32_t scrut0 = deserialize_uint32_t(ok, buf1, sz, pos);
    bool ok1 = scrut0.fst;
    uint32_t pos1 = scrut0.snd;
    uint32_t n1 = scrut0.thd;
    if (!ok1)
    {
      return
        (
          (K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_){
            .fst = false,
            .snd = pos1,
            .thd = { .sz = (uint32_t)0U, .cap = (uint32_t)0U, .vs = NULL }
          }
        );
    }
    else if (n1 == (uint32_t)0U)
    {
      return
        (
          (K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_){
            .fst = true,
            .snd = pos1,
            .thd = { .sz = (uint32_t)0U, .cap = (uint32_t)0U, .vs = NULL }
          }
        );
    }
    else
    {
      LowStar_Regional_regional__uint8_t_
      x0 = { .dummy = NULL, .r_alloc = hash_r_alloc, .r_free = hash_r_free };
      LowStar_Vector_vector_str__uint8_t_ res = LowStar_Vector_alloc__uint8_t_(n1, x0.dummy);
      K___bool_uint32_t scrut = deserialize_hash_vec_i(ok1, buf1, sz, pos1, res, (uint32_t)0U);
      bool ok2 = scrut.fst;
      uint32_t pos2 = scrut.snd;
      return
        (
          (K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_){
            .fst = ok2,
            .snd = pos2,
            .thd = res
          }
        );
    }
  }
}

static K___bool_uint32_t
deserialize_hash_vv_i(
  bool ok,
  uint8_t *buf1,
  uint32_t sz,
  uint32_t pos,
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ res,
  uint32_t i1
)
{
  if (!ok || pos >= sz)
  {
    return ((K___bool_uint32_t){ .fst = false, .snd = (uint32_t)0U });
  }
  else
  {
    K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_
    scrut = deserialize_hash_vec(ok, buf1, sz, pos);
    bool ok1 = scrut.fst;
    uint32_t pos1 = scrut.snd;
    LowStar_Vector_vector_str__uint8_t_ hv = scrut.thd;
    if (!ok1)
    {
      return ((K___bool_uint32_t){ .fst = false, .snd = pos1 });
    }
    else
    {
      LowStar_Vector_assign__LowStar_Vector_vector_str_uint8_t_(res, i1, hv);
      uint32_t j1 = i1 + (uint32_t)1U;
      if (j1 == res.sz)
      {
        return ((K___bool_uint32_t){ .fst = true, .snd = pos1 });
      }
      else
      {
        return deserialize_hash_vv_i(ok1, buf1, sz, pos1, res, j1);
      }
    }
  }
}

static LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
LowStar_Vector_alloc__LowStar_Vector_vector_str_uint8_t_(
  uint32_t len,
  LowStar_Vector_vector_str__uint8_t_ v1
)
{
  return LowStar_Vector_alloc_rid__LowStar_Vector_vector_str_uint8_t_(len, v1);
}

typedef struct
K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t__s
{
  bool fst;
  uint32_t snd;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ thd;
}
K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_;

static K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
deserialize_hash_vv(bool ok, uint8_t *buf1, uint32_t sz, uint32_t pos)
{
  if (!ok || pos >= sz)
  {
    return
      (
        (K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_){
          .fst = false,
          .snd = pos,
          .thd = { .sz = (uint32_t)0U, .cap = (uint32_t)0U, .vs = NULL }
        }
      );
  }
  else
  {
    K___bool_uint32_t_uint32_t scrut0 = deserialize_uint32_t(ok, buf1, sz, pos);
    bool ok1 = scrut0.fst;
    uint32_t pos1 = scrut0.snd;
    uint32_t n1 = scrut0.thd;
    if (!ok1)
    {
      return
        (
          (K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_){
            .fst = false,
            .snd = pos1,
            .thd = { .sz = (uint32_t)0U, .cap = (uint32_t)0U, .vs = NULL }
          }
        );
    }
    else if (n1 == (uint32_t)0U)
    {
      return
        (
          (K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_){
            .fst = true,
            .snd = pos1,
            .thd = { .sz = (uint32_t)0U, .cap = (uint32_t)0U, .vs = NULL }
          }
        );
    }
    else
    {
      LowStar_Regional_regional__LowStar_Vector_vector_str__uint8_t_
      scrut1 = { .dummy = hash_vec_dummy, .r_alloc = hash_vec_r_alloc, .r_free = hash_vec_r_free };
      LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
      res = LowStar_Vector_alloc__LowStar_Vector_vector_str_uint8_t_(n1, scrut1.dummy);
      K___bool_uint32_t scrut = deserialize_hash_vv_i(ok1, buf1, sz, pos1, res, (uint32_t)0U);
      bool ok2 = scrut.fst;
      uint32_t pos2 = scrut.snd;
      return
        (
          (K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_){
            .fst = ok2,
            .snd = pos2,
            .thd = res
          }
        );
    }
  }
}

uint64_t mt_serialize_size(merkle_tree *mt)
{
  merkle_tree mtv = *mt;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = mtv.hs;
  LowStar_Vector_vector_str__uint8_t_ rhs = mtv.rhs;
  uint64_t hs_sz = hash_vv_bytes(hs);
  if (hs_sz < (uint64_t)4294967295U)
  {
    return
      (uint64_t)21U
      + hs_sz
      + (uint64_t)1U
      + (uint64_t)4U + (uint64_t)rhs.sz * (uint64_t)hash_size
      + (uint64_t)hash_size;
  }
  else
  {
    return uint64_max;
  }
}

uint32_t mt_serialize(merkle_tree *mt, uint8_t *output, uint32_t sz)
{
  merkle_tree mtv = *mt;
  K___bool_uint32_t scrut = serialize_uint8_t(true, (uint8_t)0U, output, sz, (uint32_t)0U);
  bool ok = scrut.fst;
  uint32_t pos = scrut.snd;
  K___bool_uint32_t scrut0 = serialize_uint32_t(ok, hash_size, output, sz, pos);
  bool ok1 = scrut0.fst;
  uint32_t pos1 = scrut0.snd;
  K___bool_uint32_t scrut1 = serialize_offset_t(ok1, mtv.offset, output, sz, pos1);
  bool ok2 = scrut1.fst;
  uint32_t pos2 = scrut1.snd;
  K___bool_uint32_t scrut2 = serialize_uint32_t(ok2, mtv.i, output, sz, pos2);
  bool ok3 = scrut2.fst;
  uint32_t pos3 = scrut2.snd;
  K___bool_uint32_t scrut3 = serialize_uint32_t(ok3, mtv.j, output, sz, pos3);
  bool ok4 = scrut3.fst;
  uint32_t pos4 = scrut3.snd;
  K___bool_uint32_t scrut4 = serialize_hash_vv(ok4, mtv.hs, output, sz, pos4);
  bool ok5 = scrut4.fst;
  uint32_t pos5 = scrut4.snd;
  K___bool_uint32_t scrut5 = serialize_bool(ok5, mtv.rhs_ok, output, sz, pos5);
  bool ok6 = scrut5.fst;
  uint32_t pos6 = scrut5.snd;
  K___bool_uint32_t scrut6 = serialize_hash_vec(ok6, mtv.rhs, output, sz, pos6);
  bool ok7 = scrut6.fst;
  uint32_t pos7 = scrut6.snd;
  K___bool_uint32_t scrut7 = serialize_hash(ok7, mtv.mroot, output, sz, pos7);
  bool ok8 = scrut7.fst;
  uint32_t pos8 = scrut7.snd;
  if (ok8)
  {
    return pos8;
  }
  else
  {
    return (uint32_t)0U;
  }
}

merkle_tree *mt_deserialize(uint8_t *input, uint32_t sz)
{
  K___bool_uint32_t_uint8_t scrut0 = deserialize_uint8_t(true, input, sz, (uint32_t)0U);
  bool ok = scrut0.fst;
  uint32_t pos = scrut0.snd;
  K___bool_uint32_t_uint32_t scrut1 = deserialize_uint32_t(ok, input, sz, pos);
  bool ok1 = scrut1.fst;
  uint32_t pos1 = scrut1.snd;
  uint32_t hash_size1 = scrut1.thd;
  K___bool_uint32_t_uint64_t scrut2 = deserialize_offset_t(ok1, input, sz, pos1);
  bool ok2 = scrut2.fst;
  uint32_t pos2 = scrut2.snd;
  uint64_t offset1 = scrut2.thd;
  K___bool_uint32_t_uint32_t scrut3 = deserialize_index_t(ok2, input, sz, pos2);
  bool ok3 = scrut3.fst;
  uint32_t pos3 = scrut3.snd;
  uint32_t i1 = scrut3.thd;
  K___bool_uint32_t_uint32_t scrut4 = deserialize_index_t(ok3, input, sz, pos3);
  bool ok4 = scrut4.fst;
  uint32_t pos4 = scrut4.snd;
  uint32_t j1 = scrut4.thd;
  K___bool_uint32_t_LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_
  scrut5 = deserialize_hash_vv(ok4, input, sz, pos4);
  bool ok5 = scrut5.fst;
  uint32_t pos5 = scrut5.snd;
  LowStar_Vector_vector_str__LowStar_Vector_vector_str__uint8_t_ hs = scrut5.thd;
  K___bool_uint32_t_bool scrut6 = deserialize_bool(ok5, input, sz, pos5);
  bool ok6 = scrut6.fst;
  uint32_t pos6 = scrut6.snd;
  bool rhs_ok = scrut6.thd;
  K___bool_uint32_t_LowStar_Vector_vector_str__uint8_t_
  scrut7 = deserialize_hash_vec(ok6, input, sz, pos6);
  bool ok7 = scrut7.fst;
  uint32_t pos7 = scrut7.snd;
  LowStar_Vector_vector_str__uint8_t_ rhs = scrut7.thd;
  K___bool_uint32_t_uint8_t_ scrut = deserialize_hash(ok7, input, sz, pos7);
  bool ok8 = scrut.fst;
  uint8_t *mroot = scrut.thd;
  if
  (
    !ok8
    || hash_size1 != hash_size
    ||
      !(j1
      >= i1
      && uint64_max - offset1 >= (uint64_t)j1
      && hs.sz == (uint32_t)32U
      && rhs.sz == (uint32_t)32U)
  )
  {
    return NULL;
  }
  else
  {
    KRML_CHECK_SIZE(sizeof (merkle_tree), (uint32_t)1U);
    merkle_tree *buf = KRML_HOST_MALLOC(sizeof (merkle_tree));
    buf[0U]
    =
      (
        (merkle_tree){
          .offset = offset1,
          .i = i1,
          .j = j1,
          .hs = hs,
          .rhs_ok = rhs_ok,
          .rhs = rhs,
          .mroot = mroot
        }
      );
    return buf;
  }
}

